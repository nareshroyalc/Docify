{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ SETUP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "PROJECT: Docify - AI Documentation Generator\n",
    "ROOT: {DOCIFY_ROOT}\n",
    "\n",
    "SETUP SUMMARY:\n",
    "‚úÖ Dependencies installed: {len(successful)} packages\n",
    "‚úÖ Python paths configured\n",
    "‚úÖ Directory structure verified\n",
    "‚úÖ Core modules located\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Run 02_API_Testing.ipynb - Test backend API endpoints\n",
    "2. Run 03_Backend_Integration.ipynb - Test Gemini & Docs agents\n",
    "3. Run 04_End_to_End_Workflow.ipynb - Complete workflow demo\n",
    "4. Run 05_Frontend_Integration.ipynb - Test React frontend\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Set GEMINI_API_KEY environment variable\n",
    "- Ensure Google OAuth2 service account JSON is in Lang/ directory\n",
    "- Update .env file with necessary credentials\n",
    "\n",
    "IMPORTANT FILES:\n",
    "üìÑ Lang/config.py - Configuration settings\n",
    "üìÑ Lang/api.py - FastAPI endpoints\n",
    "üìÑ Lang/agents/gemini_agent.py - Document generation\n",
    "üìÑ Lang/agents/docs_agent.py - Google Docs formatting\n",
    "üìÑ frontend/src/App.js - React frontend\n",
    "\n",
    "For more information, check FULL_SETUP.md and README files.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Environment is ready for testing!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d13f56",
   "metadata": {},
   "source": [
    "## Step 6: Setup Summary and Next Steps\n",
    "\n",
    "Summary of completed setup and what to do next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50850cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è  CHECKING CONFIGURATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Check for .env file\n",
    "env_file = DOCIFY_ROOT / \".env\"\n",
    "if env_file.exists():\n",
    "    print(f\"‚úÖ Found .env file: {env_file}\")\n",
    "    load_dotenv(env_file)\n",
    "    print(\"   Environment variables loaded\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No .env file found at {env_file}\")\n",
    "    print(\"   Note: You'll need to set GEMINI_API_KEY and Google OAuth2 credentials\")\n",
    "\n",
    "# Check for service account JSON\n",
    "service_account_files = list(LANG_DIR.glob(\"doc-bee-*.json\"))\n",
    "if service_account_files:\n",
    "    print(f\"\\n‚úÖ Found {len(service_account_files)} service account file(s):\")\n",
    "    for f in service_account_files:\n",
    "        print(f\"   - {f.name}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No Google service account JSON file found\")\n",
    "    print(\"   Location expected: Lang/doc-bee-*.json\")\n",
    "\n",
    "# Check Python modules in Lang directory\n",
    "print(f\"\\n‚úÖ Core modules in Lang directory:\")\n",
    "core_modules = [\n",
    "    \"config.py\",\n",
    "    \"main.py\",\n",
    "    \"api.py\",\n",
    "    \"agents/gemini_agent.py\",\n",
    "    \"agents/docs_agent.py\",\n",
    "    \"utils/page_manager.py\"\n",
    "]\n",
    "\n",
    "for module in core_modules:\n",
    "    module_path = LANG_DIR / module\n",
    "    status = \"‚úÖ\" if module_path.exists() else \"‚ùå\"\n",
    "    print(f\"   {status} {module}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897748c9",
   "metadata": {},
   "source": [
    "## Step 5: Load and Verify Configuration Files\n",
    "\n",
    "Load configuration files and environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Project structure\n",
    "DOCIFY_ROOT = Path(\"d:/docify\")\n",
    "LANG_DIR = DOCIFY_ROOT / \"Lang\"\n",
    "FRONTEND_DIR = DOCIFY_ROOT / \"frontend\"\n",
    "TRADITIONAL_DIR = DOCIFY_ROOT / \"Traditional\"\n",
    "NOTEBOOKS_DIR = DOCIFY_ROOT / \"notebooks\"\n",
    "\n",
    "# Verify all critical directories exist\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÅ VERIFYING PROJECT DIRECTORY STRUCTURE\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "directories = {\n",
    "    \"Project Root\": DOCIFY_ROOT,\n",
    "    \"Lang Backend\": LANG_DIR,\n",
    "    \"Frontend\": FRONTEND_DIR,\n",
    "    \"Traditional\": TRADITIONAL_DIR,\n",
    "    \"Notebooks\": NOTEBOOKS_DIR\n",
    "}\n",
    "\n",
    "for name, path in directories.items():\n",
    "    exists = \"‚úÖ\" if path.exists() else \"‚ùå\"\n",
    "    print(f\"{exists} {name:20} {path}\")\n",
    "\n",
    "# Create notebooks directory if it doesn't exist\n",
    "NOTEBOOKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"\\n‚úÖ Notebooks directory ready: {NOTEBOOKS_DIR}\")\n",
    "\n",
    "# Add paths to sys.path for imports\n",
    "if str(LANG_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(LANG_DIR))\n",
    "\n",
    "if str(DOCIFY_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(DOCIFY_ROOT))\n",
    "\n",
    "print(f\"\\n‚úÖ Python paths configured\")\n",
    "print(f\"   - Added {LANG_DIR}\")\n",
    "print(f\"   - Added {DOCIFY_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f6c24",
   "metadata": {},
   "source": [
    "## Step 4: Set Up Project Paths and Configuration\n",
    "\n",
    "Configure paths and environment variables needed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ VERIFYING CRITICAL PACKAGES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "packages_to_verify = {\n",
    "    \"fastapi\": \"FastAPI Web Framework\",\n",
    "    \"uvicorn\": \"ASGI Server\",\n",
    "    \"pydantic\": \"Data Validation\",\n",
    "    \"langchain\": \"LangChain Framework\",\n",
    "    \"langchain_core\": \"LangChain Core\",\n",
    "    \"langchain_google_genai\": \"LangChain Google GenAI\",\n",
    "    \"google.generativeai\": \"Google Generative AI\",\n",
    "    \"google.auth\": \"Google Authentication\",\n",
    "    \"google.oauth2\": \"Google OAuth2\",\n",
    "    \"googleapiclient\": \"Google API Client\",\n",
    "    \"dotenv\": \"Python Dotenv\"\n",
    "}\n",
    "\n",
    "import importlib\n",
    "\n",
    "verified = {}\n",
    "failed_imports = {}\n",
    "\n",
    "for module_name, description in packages_to_verify.items():\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        version = getattr(module, '__version__', 'version not available')\n",
    "        verified[module_name] = version\n",
    "        print(f\"‚úÖ {module_name:30} {description:30} [{version}]\")\n",
    "    except ImportError as e:\n",
    "        failed_imports[module_name] = str(e)\n",
    "        print(f\"‚ùå {module_name:30} {description:30} [FAILED]\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Verified: {len(verified)} packages\")\n",
    "print(f\"‚ùå Failed: {len(failed_imports)} packages\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4667347",
   "metadata": {},
   "source": [
    "## Step 3: Import and Verify All Packages\n",
    "\n",
    "Verify that all critical packages are installed and working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca010cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def install_requirements(requirements_list):\n",
    "    \"\"\"Install packages from requirements list\"\"\"\n",
    "    failed_packages = []\n",
    "    successful_packages = []\n",
    "    \n",
    "    print(f\"\\nüì¶ INSTALLING {len(requirements_list)} DEPENDENCIES\\n\")\n",
    "    \n",
    "    for i, req in enumerate(sorted(requirements_list), 1):\n",
    "        print(f\"[{i}/{len(requirements_list)}] Installing: {req}\", end=\" ... \")\n",
    "        try:\n",
    "            # Install the requirement silently\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", req],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=120\n",
    "            )\n",
    "            if result.returncode == 0:\n",
    "                print(\"‚úÖ\")\n",
    "                successful_packages.append(req)\n",
    "            else:\n",
    "                print(\"‚ùå\")\n",
    "                failed_packages.append((req, result.stderr))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå (Error: {str(e)[:50]})\")\n",
    "            failed_packages.append((req, str(e)))\n",
    "    \n",
    "    return successful_packages, failed_packages\n",
    "\n",
    "# Install all unique requirements\n",
    "successful, failed = install_requirements(sorted(all_requirements))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Successfully installed: {len(successful)} packages\")\n",
    "print(f\"‚ùå Failed to install: {len(failed)} packages\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\n‚ö†Ô∏è  Failed packages:\")\n",
    "    for pkg, error in failed:\n",
    "        print(f\"  - {pkg}\")\n",
    "        if error:\n",
    "            print(f\"    Error: {error[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e898bccf",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "Install all dependencies from the requirements files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a893c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_requirements(file_path):\n",
    "    \"\"\"Read and parse requirements.txt file\"\"\"\n",
    "    requirements = []\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                # Skip comments and empty lines\n",
    "                if line and not line.startswith('#'):\n",
    "                    requirements.append(line)\n",
    "        return requirements\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "# Define paths\n",
    "docify_root = Path(\"d:/docify\")\n",
    "root_requirements = docify_root / \"requirements.txt\"\n",
    "lang_requirements = docify_root / \"Lang\" / \"requirements.txt\"\n",
    "lang_api_requirements = docify_root / \"Lang\" / \"requirements-api.txt\"\n",
    "\n",
    "# Read all requirements\n",
    "print(\"\\nüìã READING REQUIREMENTS FILES\\n\")\n",
    "\n",
    "print(f\"1. Root requirements.txt: {root_requirements}\")\n",
    "root_reqs = read_requirements(root_requirements)\n",
    "if root_reqs:\n",
    "    print(f\"   Found {len(root_reqs)} dependencies:\")\n",
    "    for req in root_reqs:\n",
    "        print(f\"   - {req}\")\n",
    "else:\n",
    "    print(\"   ‚ùå File not found\")\n",
    "\n",
    "print(f\"\\n2. Lang/requirements.txt: {lang_requirements}\")\n",
    "lang_reqs = read_requirements(lang_requirements)\n",
    "if lang_reqs:\n",
    "    print(f\"   Found {len(lang_reqs)} dependencies:\")\n",
    "    for req in lang_reqs:\n",
    "        print(f\"   - {req}\")\n",
    "else:\n",
    "    print(\"   ‚ùå File not found\")\n",
    "\n",
    "print(f\"\\n3. Lang/requirements-api.txt: {lang_api_requirements}\")\n",
    "lang_api_reqs = read_requirements(lang_api_requirements)\n",
    "if lang_api_reqs:\n",
    "    print(f\"   Found {len(lang_api_reqs)} dependencies:\")\n",
    "    for req in lang_api_reqs:\n",
    "        print(f\"   - {req}\")\n",
    "else:\n",
    "    print(\"   ‚ùå File not found\")\n",
    "\n",
    "# Combine all unique requirements\n",
    "all_requirements = set()\n",
    "if root_reqs:\n",
    "    all_requirements.update(root_reqs)\n",
    "if lang_reqs:\n",
    "    all_requirements.update(lang_reqs)\n",
    "if lang_api_reqs:\n",
    "    all_requirements.update(lang_api_reqs)\n",
    "\n",
    "print(f\"\\n‚úÖ Total unique dependencies to install: {len(all_requirements)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1f674",
   "metadata": {},
   "source": [
    "## Step 1: Read and Parse Requirements Files\n",
    "\n",
    "We'll read the requirements.txt files from both root and Lang directories to understand all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ede9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Display Python and system info\n",
    "print(\"=\" * 60)\n",
    "print(\"DOCIFY PROJECT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c15ae5",
   "metadata": {},
   "source": [
    "# Docify: Complete Setup & Environment Configuration\n",
    "## From Requirements.txt to Full Environment Ready\n",
    "\n",
    "This notebook handles the complete setup process for the Docify project, including:\n",
    "- Reading and parsing requirements.txt files\n",
    "- Installing all dependencies\n",
    "- Verifying installations\n",
    "- Setting up configuration and environment variables\n",
    "- Creating necessary directories"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
